#!/usr/bin/env python3
# coding=utf-8
import os
import sys
import argparse
import time

try:
    from MAnormFast.MAnorm_io import *
    from MAnormFast.peaks import *
    from MAnormFast import version
except ImportError:
    sys.path.insert(0, os.path.dirname(os.path.realpath(__file__))[:-3])
    from lib.MAnorm_io import *
    from lib.peaks import *
    from lib import version


def __parse_args():
    parser = argparse.ArgumentParser(description='MAnorm Fast version')
    parser.add_argument(
        '--p1', dest='pkf1',
        help='numerator peaks file path, It should contain at least three '
             'columns, which are chromosome name, start and end position of '
             'each peak. If the fourth column exists, it should be summit '
             'position (relative to peak start). Otherwise, MAnorm will use '
             'the center of peaks instead.'
    )
    parser.add_argument(
        '--p2', dest='pkf2',
        help='denominator peaks file path'
    )
    parser.add_argument(
        '--r1', dest='rdf1',
        help='numerator reads file path, It should be of bed format, in which '
             'the first, second, third and sixth columns are the chromosome, '
             'start, end and strand, respectively.'
    )
    parser.add_argument(
        '--r2', dest='rdf2',
        help='denominator reads file path'
    )
    parser.add_argument(
        '--s1', dest='sft1', type=int, default=100,
        help='read shift size of sample 1, which should be set as the average '
             'size of DNA fragments, default=100.'
    )
    parser.add_argument(
        '--s2', dest='sft2', type=int, default=100,
        help='read shift size of sample 2, default=100.'
    )
    parser.add_argument(
        '-n', dest='random_time', type=int, default=5,
        help='number of random permutations to test the enrichment of '
             'overlapping between two peak sets, default=5.'
    )
    parser.add_argument(
        '-o', dest='output',
        help='Name of this comparison, which will be also used as the name '
             'of folder created to store.'
    )
    parser.add_argument(
        '-e', dest='extension', type=int, default=1000,
        help='default=1000, 2*extension=size of the window centered at peak '
             'summit to calculate reads density. The window size should match '
             'the typical length of peaks, thus we recommend extension=1000 '
             'for sharp histone marks like H3K4me2/3 or H3K9/27ac, '
             'extension=500 for transcription factor or DNase-seq.'
    )
    parser.add_argument(
        '-d', dest='smt_dist', type=int,
        help='summit to summit distance cutoff, default=extension/2. '
             'Only those common peaks with distance between their summits in '
             '2 samples smaller than this value will be considered as real '
             'common peaks for building the normalization model.'
    )
    parser.add_argument(
        '-s', dest='output_no_merge', action='store_true',
        default=False,
        help='By default, MAnorm will first separate both sets of input peaks '
             'into common and unique peaks, by checking whether they have '
             'overlap with any peak in the other sample, and then merge the 2 '
             'sets of  peaks into 1 group of non-overlapping ones. But if this '
             'option is used, MAnorm would not merge the common peaks and the '
             'peaks in output files will be exactly the same as those from '
             'input.'
    )
    parser.add_argument(
        '-v', dest='overlap_dependent', action='store_true',
        default=False,
        help='if this option is used, MAnorm will choose biased peaks only '
             'from unique peaks, and '
             'choose unbiased peaks only from common peaks. But if this option '
             'is not used, MAnorm '
             'will choose biased and unbiased peaks just based on the M-value '
             'and P-value cutoffs, '
             'without checking whether they are common or unique peaks.'
    )
    parser.add_argument(
        '-p', dest='biased_p', type=float, default=0.01,
        help='Cutoff of P-value to define biased (high-confidence sample 1 '
             'or 2-specific) peaks, '
             'default=0.01.'
    )
    parser.add_argument(
        '-m', dest='biased_m', type=float, default=1.,
        help='Cutoff of M-value to define biased peaks, default=1. Sample 1 '
             'biased peaks are defined '
             'as sample 1 unique peaks with M-value > mcut_biased and '
             'P-value < pcut_biased, while '
             'sample 2 biased peaks are defined as sample 2 unique peaks with '
             'M-value < -1*mcut_biased and P-value < pcut_biased.'
    )
    parser.add_argument(
        '-u', dest='unbiased_m', type=float, default=1.,
        help='Cutoff of M-value to define unbiased '
             '(high-confidence non-specific) peaks'
             'between 2 samples, default=1. They are defined to be the '
             'common peaks with'
             ' -1*mcut_unbiased < M-value < mcut_unbiased and '
             'P-value > pcut_biased.'
    )

    return parser.parse_args()


def command():
    args = __parse_args()
    numerator_peaks_fp = args.pkf1
    denominator_peaks_fp = args.pkf2
    numerator_reads_fp = args.rdf1
    denominator_reads_fp = args.rdf2
    shift1, shift2 = args.sft1, args.sft2
    random_time = args.random_time
    output_folder = args.output
    ext = args.extension
    min_smt_dist = args.smt_dist if args.smt_dist is not None else ext // 2
    output_no_merge = args.output_no_merge
    overlap_dependent = args.overlap_dependent
    biased_pvalue = args.biased_p
    biased_mvalue = args.biased_m
    unbiased_mvalue = args.unbiased_m

    try:
        os.mkdir(output_folder)
    except OSError:
        print(f'@error: folder name "{output_folder}" already exist, please change the '
              'output folder name!')
        exit(0)

    start = time.perf_counter()

    pks1_fn, pks2_fn = \
        os.path.basename(numerator_peaks_fp), os.path.basename(
            denominator_peaks_fp)
    rds1_fn, rds2_fn = \
        os.path.basename(numerator_reads_fp), os.path.basename(
            denominator_reads_fp)
    print('\n'
          '# ARGUMENT LIST:\n'
          f'# numerator peaks file={pks1_fn}\n'
          f'# denominator peaks file={pks2_fn}\n'
          f'# numerator reads file={rds1_fn}\n'
          f'# denominator reads file={rds2_fn}\n'
          f'# shift size of numerator reads={shift1}\n'
          f'# shift size of denominator reads={shift2}\n'
          f'# extension size of peak={ext}\n'
          f'# min summit to summit distance={min_smt_dist}\n'
          f'# output folder name={output_folder}\n')

    pks1_fn = pks1_fn.split('.')[0].replace(' ', '_')
    pks2_fn = pks2_fn.split('.')[0].replace(' ', '_')
    rds1_fn = rds1_fn.split('.')[0].replace(' ', '_')
    rds2_fn = rds2_fn.split('.')[0].replace(' ', '_')

    print('Reading Data, please wait for a while...')
    pks1, pks2 = \
        read_peaks(numerator_peaks_fp), \
        read_peaks(denominator_peaks_fp)
    reads_pos1, reads_pos2 = \
        read_reads(numerator_reads_fp, shift1), \
        read_reads(denominator_reads_fp, shift2)

    print('Step1: Classify the 2 peaks by overlap')
    pks1_uniq, pks1_com, pks2_uniq, pks2_com = get_common_peaks(pks1, pks2)
    print(f'{pks1_fn}: {get_peaks_size(pks1_uniq)}(unique) {get_peaks_size(pks1_com)}(common)\n'
          f'{pks2_fn}: {get_peaks_size(pks2_uniq)}(unique) {get_peaks_size(pks2_com)}(common)')
    time.sleep(2)

    print(f'Step2: Random overlap testing, test time is {random_time}')
    fcs = []
    for _ in range(random_time):
        pks2_random = randomize_peaks(pks2)
        pks1_com_new = get_common_peaks(pks1, pks2_random)[1]
        fcs.append(
            1. * get_peaks_size(pks1_com) / (get_peaks_size(pks1_com_new) + 0.1)
        )  # 加0.1避免出现分母为零的情况
    print('fold change: mean={0:f}, std={1:f}'.format(
        np.array(fcs).mean(),
        np.array(fcs).std()
    ))
    time.sleep(2)

    print('Step3: Merging common peaks')
    merged_pks, summit2summit_dist = merge_common_peaks(pks1_com, pks2_com)
    print(f'merged peaks: {get_peaks_size(merged_pks)}')
    if get_peaks_size(merged_pks) == 0:
        print('@Error: No common peaks!!')
        exit(1)
    time.sleep(2)

    print('Step4: Calculating peaks read density')
    cal_peaks_read_density(pks1, reads_pos1, reads_pos2, ext)
    cal_peaks_read_density(pks2, reads_pos1, reads_pos2, ext)
    cal_peaks_read_density(merged_pks, reads_pos1, reads_pos2, ext)
    time.sleep(2)

    print('Step5: Using merged common peaks to fitting all peaks')
    ma_fit = use_merged_peaks_fit_model(
        merged_pks, summit2summit_dist, min_smt_dist
    )
    if ma_fit[0] >= 0:
        print('Model for normalization: '
              f'M = {ma_fit[1]:f} * A + {ma_fit[0]:f}')
    else:
        print('Model for normalization: '
              f'M = {ma_fit[1]:f} * A - {abs(ma_fit[0]):f}')
    time.sleep(2)

    print('Step6: Normalizing all peaks')
    normalize_peaks(pks1, ma_fit)
    normalize_peaks(pks2, ma_fit)
    normalize_peaks(merged_pks, ma_fit)
    time.sleep(2)

    print('Step7: Output result')
    os.chdir(output_folder)
    if output_no_merge:
        output_normalized_peaks(
            pks1_uniq, pks1_com, pks1_fn + '_MAvalues.xls', rds1_fn, rds2_fn
        )
        output_normalized_peaks(
            pks2_uniq, pks2_com, pks2_fn + '_MAvalues.xls', rds1_fn, rds2_fn
        )
    output_3set_normalized_peaks(
        pks1_uniq, merged_pks, pks2_uniq,
        output_folder + '_all_peak_MAvalues.xls',
        pks1_fn, pks2_fn, rds1_fn, rds2_fn
    )
    os.mkdir('output_figures')
    os.mkdir('output_filters')
    os.mkdir('output_wig_files')
    os.chdir('output_figures')
    draw_figs_to_show_data(
        pks1_uniq, pks2_uniq,
        merged_pks,
        pks1_fn, pks2_fn,
        ma_fit,
        rds1_fn, rds2_fn
    )
    os.chdir('..')
    os.chdir('output_wig_files')
    output_peaks_mvalue_2wig_file(
        pks1_uniq, pks2_uniq, merged_pks, output_folder
    )
    os.chdir('..')
    os.chdir('output_filters')
    output_unbiased_peaks(
        pks1_uniq, pks2_uniq, merged_pks, unbiased_mvalue, overlap_dependent
    )
    output_biased_peaks(
        pks1_uniq, pks2_uniq,
        merged_pks,
        biased_mvalue, biased_pvalue,
        overlap_dependent
    )
    print(f'time consumption: {time.perf_counter() - start:.2f} s\nDone!')


if __name__ == '__main__':
    command()
